{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c12aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction train avec Stochoastic Gradient Descent\n",
    "def TrainSGD(x, y, lr, epoch):\n",
    "    m = len(y)\n",
    "    x = add_ones(x.values)\n",
    "    theta = np.zeros(x.shape[1])\n",
    "    cost_history = np.zeros(epoch)\n",
    "\n",
    "    for i in range(epoch):\n",
    "        for j in range(m):\n",
    "            rand_index = np.random.randint(0, m)\n",
    "            x_sample = x[rand_index, :]\n",
    "            y_sample = y[rand_index]\n",
    "            error = x_sample.dot(theta) - y_sample\n",
    "            gradient = x_sample * error\n",
    "            theta_new = theta - lr * gradient\n",
    "            theta = theta_new\n",
    "\n",
    "        cost_history[i] = compute_cost(x, y, theta)\n",
    "\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction\n",
    "def Train(self, X, y):\n",
    "    m = len\n",
    "    X = self.add_ones(X.values)\n",
    "    self.theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    self.cost_history = np.zeros(self.epoch)\n",
    "    for i in range(self.epoch):\n",
    "        np.random.seed(3)\n",
    "        perm = np.random.permutation(len(X_train))\n",
    "        X = X[perm]\n",
    "        y = y.iloc[perm]\n",
    "        for j in range(len(X)):\n",
    "            theta_new = self.theta - self.lr*X[j].T.dot(X[j].dot(self.theta) - y.iloc[j])\n",
    "            self.theta = theta_new \n",
    "            self.cost_history[i] = self.compute_cost(X, y,self.theta)\n",
    "            \n",
    "    return  self.theta, self.cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f03ebb",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h2> 2. Reprendre la regression linéaire avec scikit-learn. </h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ad1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires :\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier `data.xlsx` et sauver son contenu dans la varisble `data`\n",
    "data = pd.read_excel(\"data.xlsx\")\n",
    "\n",
    "# Afficher le dataframe\n",
    "data.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récuperer la colonne à prédire Y\n",
    "Y = data.pop('Y')\n",
    "\n",
    "# Selectionner les colonnes sur lesquelles notre prédiction séra basée\n",
    "X = data.values\n",
    "\n",
    "# Afficher les features\n",
    "# display (y)\n",
    "# display (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ccccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partager les données en deux parties : une pour l'apprentissage (train) et une autre pour le test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(Y_train))\n",
    "print(len(Y_test))\n",
    "\n",
    "print ()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab378f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le model \n",
    "lin_regr = LinearRegression()\n",
    "\n",
    "# On fit (entraine) le modele (apprentissage)\n",
    "lin_regr.fit(X_train, Y_train)\n",
    "\n",
    "# Prédir la valeur de Y\n",
    "y_predict = lin_regr.predict(X_test)\n",
    "\n",
    "# Afficher la valeur prédite\n",
    "display(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error (mse) : l'erreur moyenne au carrée\n",
    "mse = mean_squared_error (Y_test, y_predict)\n",
    "print (\"Mean Squared Error :\", mse)\n",
    "\n",
    "# Root Mean Squared Error (rmse) : la racine carrée de l'erreur moyenne au carrée\n",
    "rmse = np.sqrt(mse)\n",
    "print (\"Root Mean Squared Error\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix du graph\n",
    "# plt.scatter(y_predict, Y_test)\n",
    "plt.scatter(Y_test, y_predict)\n",
    "\n",
    "plt.plot (np.arange (20000))\n",
    "# Labels\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a076ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91a14012",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h2> 3. Reprendre la regression logistique avec scikit-learn. </h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880eaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0beaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données du fichier diabetes.csv\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "data.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récuperer les colonnes sur lesquelles la prédiction sera faite dans X et celle à rédire dans Y\n",
    "X = data.drop (\"Outcome\", axis = 1)\n",
    "Y = data [[\"Outcome\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ba5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les données : celles d'apprentissage d'un côté et celles de test d'un autre côté \n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.30, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le modèle : Regression Logistique\n",
    "log_regr = LogisticRegression ()\n",
    "log_regr.fit (X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b154d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les valeurs de Y\n",
    "y_predict = log_regr.predict (X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc658aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X_test, y_predict, color='red')\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_mat = metrics.confusion_matrix (Y_test, y_predict)\n",
    "\n",
    "# Représentation graphique de la matrice de confusion\n",
    "plt.figure (figsize = (10,6))\n",
    "plt.title (\"Matrice de confudsion\")\n",
    "sns.heatmap (conf_mat, annot = True, fmt = 'd', cmap = 'Blues')\n",
    "plt.ylabel (\"Valeurs réeles\")\n",
    "plt.xlabel (\"Valueurs prédites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b114192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c52d3b7f",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h2>4. Reprendre l'Analyse de la Composante Principale (ACP) avec scikit-learn</h2></center>\n",
    "<center><h3>Principal Component Analysis (PCA)</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer les bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv ('data.csv')\n",
    "\n",
    "# Les dimensions des données avant la transformation avec PCA\n",
    "print(\"Dimensions avant transformation :\", data.shape)\n",
    "data.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a03bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les données dans leur état actuel\n",
    "sns.scatterplot\n",
    "\n",
    "plt.figure (figsize = (10, 6))\n",
    "plt.style.use ('ggplot')\n",
    "sns.scatterplot (data = data, x = 'f1', y = 'f2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les données avand d'appliquer le PAC\n",
    "x_scaled = StandardScaler()\n",
    " \n",
    "# Appeler les fonction fit () et transform () pour transformer les données\n",
    "x_scaled.fit (data)\n",
    "x_scaled = x_scaled.transform (data)\n",
    " \n",
    "# Appliquer le PCA avec n_components = 2\n",
    "pca = PCA (n_components = 2)\n",
    "pca.fit (x_scaled)\n",
    "principal_df = pca.transform (z)\n",
    " \n",
    "# Vérifier les dimensions après la transformation avec PCA\n",
    "print(\"Dimensions après transformation :\", principal_df.shape)\n",
    "\n",
    "pca_df = pd.DataFrame(data = principal_df, columns=['PCA1', 'PCA2'])\n",
    "pca_df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les valeurs des vecteurs propres produits par les composantes principales\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuliser les données transformées\n",
    "plt.figure (figsize = (10, 6))\n",
    "plt.style.use ('ggplot')\n",
    "sns.scatterplot (data = pca, x = 'PCA1', y = 'PCA2', hue = 'PCA2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e917e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
